{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03B.HyperTuning-AB.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EIq2jbKU15dq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Input : </b></h2>\n",
        "\n",
        "*   train_microarray.csv\n",
        "*   ab1_features.pkl\n",
        "*   ab2_features.pkl\n",
        "*   ab3_features.pkl\n",
        "\n",
        "<h2><b>Output : </b></h2>\n",
        "\n",
        "*   ab1_model.pkl\n",
        "*   ab2_model.pkl\n",
        "*   ab3_model.pkl"
      ],
      "metadata": {
        "id": "eeijAryBPe-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run All"
      ],
      "metadata": {
        "id": "Q2nVT3qquJVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dan Load"
      ],
      "metadata": {
        "id": "VPPsV-sQuLvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import library yang diperlukan"
      ],
      "metadata": {
        "id": "mRxAAnfBUWcu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3Tq4Rn-tAih"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib import rcParams\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengatur Style"
      ],
      "metadata": {
        "id": "0ukTTQg6j0lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rcParams['figure.figsize'] = 15, 8\n",
        "mpl.style.use(['ggplot'])"
      ],
      "metadata": {
        "id": "In2laP_Cjz4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data train"
      ],
      "metadata": {
        "id": "pcKdyCcpUZQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('https://drive.google.com/uc?id=1_r9KdY3hz2zVtCD6VZs2nHrnXBGbia8v')"
      ],
      "metadata": {
        "id": "EnX3N48tub-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load hasil seleksi fitur"
      ],
      "metadata": {
        "id": "mgu-uM6KUfKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab1_features = joblib.load('ab1_features.pkl')\n",
        "ab2_features = joblib.load('ab2_features.pkl')\n",
        "ab3_features = joblib.load('ab3_features.pkl')"
      ],
      "metadata": {
        "id": "H9AW_8vdmKM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Df_train dengan fitur 1"
      ],
      "metadata": {
        "id": "k_H4f1LuUl-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train1 = df_train[ab1_features]\n",
        "df_train1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "iei5Qvs3ut0G",
        "outputId": "cd7c1bd9-cc7c-41fd-b8a6-455b3e60d914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   219678_x_at  217653_x_at  211996_s_at  214594_x_at  218155_x_at  \\\n",
              "0     2.672850     2.223647     2.894223     2.730180     2.708516   \n",
              "1     2.641439     2.350872     3.042087     2.856150     2.800348   \n",
              "2     2.510368     1.996011     2.624352     2.491994     2.648607   \n",
              "3     2.747069     2.666440     2.893101     2.998907     2.992614   \n",
              "4     2.785209     2.600757     3.116527     2.977250     2.859183   \n",
              "\n",
              "   207730_x_at  216609_at  207953_at  217679_x_at  210168_at  ...  \\\n",
              "0     3.043026   2.318040   2.462324     2.748249   2.698125  ...   \n",
              "1     3.129235   2.306733   2.476773     2.884853   2.293900  ...   \n",
              "2     2.921754   2.231919   2.371051     2.482992   2.399431  ...   \n",
              "3     3.307086   1.966337   2.863540     3.172937   2.521457  ...   \n",
              "4     3.216666   2.424350   2.650209     2.929251   2.155440  ...   \n",
              "\n",
              "   206544_x_at  200598_s_at  212515_s_at  213872_at  202435_s_at  211505_s_at  \\\n",
              "0     2.584677     2.614547     2.459196   2.371555     1.859862     2.449663   \n",
              "1     2.541014     2.464834     2.651054   2.249695     1.991560     2.262768   \n",
              "2     2.408422     2.665663     2.371579   2.046329     2.353558     2.198965   \n",
              "3     2.314931     2.019661     2.192755   2.209179     1.973821     1.916729   \n",
              "4     2.305571     2.192273     2.404168   2.183277     2.610495     1.939796   \n",
              "\n",
              "   40665_at  208654_s_at  202817_s_at  Label  \n",
              "0  2.464299     2.940958     2.116067    1.0  \n",
              "1  2.172416     2.875015     2.354635    0.0  \n",
              "2  2.246445     2.710852     1.743328    1.0  \n",
              "3  1.719003     2.110986     1.904847    1.0  \n",
              "4  1.736053     2.456737     1.935020    0.0  \n",
              "\n",
              "[5 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-260afbde-b242-482b-a9e7-41153f4f6639\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>219678_x_at</th>\n",
              "      <th>217653_x_at</th>\n",
              "      <th>211996_s_at</th>\n",
              "      <th>214594_x_at</th>\n",
              "      <th>218155_x_at</th>\n",
              "      <th>207730_x_at</th>\n",
              "      <th>216609_at</th>\n",
              "      <th>207953_at</th>\n",
              "      <th>217679_x_at</th>\n",
              "      <th>210168_at</th>\n",
              "      <th>...</th>\n",
              "      <th>206544_x_at</th>\n",
              "      <th>200598_s_at</th>\n",
              "      <th>212515_s_at</th>\n",
              "      <th>213872_at</th>\n",
              "      <th>202435_s_at</th>\n",
              "      <th>211505_s_at</th>\n",
              "      <th>40665_at</th>\n",
              "      <th>208654_s_at</th>\n",
              "      <th>202817_s_at</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.672850</td>\n",
              "      <td>2.223647</td>\n",
              "      <td>2.894223</td>\n",
              "      <td>2.730180</td>\n",
              "      <td>2.708516</td>\n",
              "      <td>3.043026</td>\n",
              "      <td>2.318040</td>\n",
              "      <td>2.462324</td>\n",
              "      <td>2.748249</td>\n",
              "      <td>2.698125</td>\n",
              "      <td>...</td>\n",
              "      <td>2.584677</td>\n",
              "      <td>2.614547</td>\n",
              "      <td>2.459196</td>\n",
              "      <td>2.371555</td>\n",
              "      <td>1.859862</td>\n",
              "      <td>2.449663</td>\n",
              "      <td>2.464299</td>\n",
              "      <td>2.940958</td>\n",
              "      <td>2.116067</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.641439</td>\n",
              "      <td>2.350872</td>\n",
              "      <td>3.042087</td>\n",
              "      <td>2.856150</td>\n",
              "      <td>2.800348</td>\n",
              "      <td>3.129235</td>\n",
              "      <td>2.306733</td>\n",
              "      <td>2.476773</td>\n",
              "      <td>2.884853</td>\n",
              "      <td>2.293900</td>\n",
              "      <td>...</td>\n",
              "      <td>2.541014</td>\n",
              "      <td>2.464834</td>\n",
              "      <td>2.651054</td>\n",
              "      <td>2.249695</td>\n",
              "      <td>1.991560</td>\n",
              "      <td>2.262768</td>\n",
              "      <td>2.172416</td>\n",
              "      <td>2.875015</td>\n",
              "      <td>2.354635</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.510368</td>\n",
              "      <td>1.996011</td>\n",
              "      <td>2.624352</td>\n",
              "      <td>2.491994</td>\n",
              "      <td>2.648607</td>\n",
              "      <td>2.921754</td>\n",
              "      <td>2.231919</td>\n",
              "      <td>2.371051</td>\n",
              "      <td>2.482992</td>\n",
              "      <td>2.399431</td>\n",
              "      <td>...</td>\n",
              "      <td>2.408422</td>\n",
              "      <td>2.665663</td>\n",
              "      <td>2.371579</td>\n",
              "      <td>2.046329</td>\n",
              "      <td>2.353558</td>\n",
              "      <td>2.198965</td>\n",
              "      <td>2.246445</td>\n",
              "      <td>2.710852</td>\n",
              "      <td>1.743328</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.747069</td>\n",
              "      <td>2.666440</td>\n",
              "      <td>2.893101</td>\n",
              "      <td>2.998907</td>\n",
              "      <td>2.992614</td>\n",
              "      <td>3.307086</td>\n",
              "      <td>1.966337</td>\n",
              "      <td>2.863540</td>\n",
              "      <td>3.172937</td>\n",
              "      <td>2.521457</td>\n",
              "      <td>...</td>\n",
              "      <td>2.314931</td>\n",
              "      <td>2.019661</td>\n",
              "      <td>2.192755</td>\n",
              "      <td>2.209179</td>\n",
              "      <td>1.973821</td>\n",
              "      <td>1.916729</td>\n",
              "      <td>1.719003</td>\n",
              "      <td>2.110986</td>\n",
              "      <td>1.904847</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.785209</td>\n",
              "      <td>2.600757</td>\n",
              "      <td>3.116527</td>\n",
              "      <td>2.977250</td>\n",
              "      <td>2.859183</td>\n",
              "      <td>3.216666</td>\n",
              "      <td>2.424350</td>\n",
              "      <td>2.650209</td>\n",
              "      <td>2.929251</td>\n",
              "      <td>2.155440</td>\n",
              "      <td>...</td>\n",
              "      <td>2.305571</td>\n",
              "      <td>2.192273</td>\n",
              "      <td>2.404168</td>\n",
              "      <td>2.183277</td>\n",
              "      <td>2.610495</td>\n",
              "      <td>1.939796</td>\n",
              "      <td>1.736053</td>\n",
              "      <td>2.456737</td>\n",
              "      <td>1.935020</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-260afbde-b242-482b-a9e7-41153f4f6639')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-260afbde-b242-482b-a9e7-41153f4f6639 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-260afbde-b242-482b-a9e7-41153f4f6639');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Df_train dengan fitur 2"
      ],
      "metadata": {
        "id": "isfgGz66WG5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train2 = df_train[ab2_features]\n",
        "df_train2.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "836DjPzPUNTi",
        "outputId": "31f19d38-9c86-4164-a1cb-b35b6547c8da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   211612_s_at  219678_x_at  217653_x_at  211996_s_at  214594_x_at  \\\n",
              "0     2.433180     2.672850     2.223647     2.894223     2.730180   \n",
              "1     2.261091     2.641439     2.350872     3.042087     2.856150   \n",
              "2     2.385914     2.510368     1.996011     2.624352     2.491994   \n",
              "3     2.262845     2.747069     2.666440     2.893101     2.998907   \n",
              "4     2.239799     2.785209     2.600757     3.116527     2.977250   \n",
              "\n",
              "   218155_x_at  202936_s_at  207730_x_at  205401_at  216609_at  ...  \\\n",
              "0     2.708516     2.677585     3.043026   2.277064   2.318040  ...   \n",
              "1     2.800348     2.392170     3.129235   2.249331   2.306733  ...   \n",
              "2     2.648607     2.355828     2.921754   2.316953   2.231919  ...   \n",
              "3     2.992614     2.352489     3.307086   2.165011   1.966337  ...   \n",
              "4     2.859183     2.296027     3.216666   2.221606   2.424350  ...   \n",
              "\n",
              "   208671_at  211505_s_at  40665_at  214830_at  208654_s_at  202131_s_at  \\\n",
              "0   2.547195     2.449663  2.464299   2.316326     2.940958     2.170559   \n",
              "1   2.535646     2.262768  2.172416   2.248017     2.875015     2.089126   \n",
              "2   2.634353     2.198965  2.246445   2.327131     2.710852     1.971494   \n",
              "3   1.876583     1.916729  1.719003   1.774782     2.110986     1.840146   \n",
              "4   2.242884     1.939796  1.736053   2.100648     2.456737     2.037821   \n",
              "\n",
              "   202817_s_at  34031_i_at  201339_s_at  Label  \n",
              "0     2.116067    2.136241     2.794302    1.0  \n",
              "1     2.354635    2.106757     2.788661    0.0  \n",
              "2     1.743328    2.098736     2.921265    1.0  \n",
              "3     1.904847    1.471070     1.703865    1.0  \n",
              "4     1.935020    1.968626     2.395988    0.0  \n",
              "\n",
              "[5 rows x 401 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03e1a229-d5d7-4fe1-beb6-eec56dd3292b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>211612_s_at</th>\n",
              "      <th>219678_x_at</th>\n",
              "      <th>217653_x_at</th>\n",
              "      <th>211996_s_at</th>\n",
              "      <th>214594_x_at</th>\n",
              "      <th>218155_x_at</th>\n",
              "      <th>202936_s_at</th>\n",
              "      <th>207730_x_at</th>\n",
              "      <th>205401_at</th>\n",
              "      <th>216609_at</th>\n",
              "      <th>...</th>\n",
              "      <th>208671_at</th>\n",
              "      <th>211505_s_at</th>\n",
              "      <th>40665_at</th>\n",
              "      <th>214830_at</th>\n",
              "      <th>208654_s_at</th>\n",
              "      <th>202131_s_at</th>\n",
              "      <th>202817_s_at</th>\n",
              "      <th>34031_i_at</th>\n",
              "      <th>201339_s_at</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.433180</td>\n",
              "      <td>2.672850</td>\n",
              "      <td>2.223647</td>\n",
              "      <td>2.894223</td>\n",
              "      <td>2.730180</td>\n",
              "      <td>2.708516</td>\n",
              "      <td>2.677585</td>\n",
              "      <td>3.043026</td>\n",
              "      <td>2.277064</td>\n",
              "      <td>2.318040</td>\n",
              "      <td>...</td>\n",
              "      <td>2.547195</td>\n",
              "      <td>2.449663</td>\n",
              "      <td>2.464299</td>\n",
              "      <td>2.316326</td>\n",
              "      <td>2.940958</td>\n",
              "      <td>2.170559</td>\n",
              "      <td>2.116067</td>\n",
              "      <td>2.136241</td>\n",
              "      <td>2.794302</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.261091</td>\n",
              "      <td>2.641439</td>\n",
              "      <td>2.350872</td>\n",
              "      <td>3.042087</td>\n",
              "      <td>2.856150</td>\n",
              "      <td>2.800348</td>\n",
              "      <td>2.392170</td>\n",
              "      <td>3.129235</td>\n",
              "      <td>2.249331</td>\n",
              "      <td>2.306733</td>\n",
              "      <td>...</td>\n",
              "      <td>2.535646</td>\n",
              "      <td>2.262768</td>\n",
              "      <td>2.172416</td>\n",
              "      <td>2.248017</td>\n",
              "      <td>2.875015</td>\n",
              "      <td>2.089126</td>\n",
              "      <td>2.354635</td>\n",
              "      <td>2.106757</td>\n",
              "      <td>2.788661</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.385914</td>\n",
              "      <td>2.510368</td>\n",
              "      <td>1.996011</td>\n",
              "      <td>2.624352</td>\n",
              "      <td>2.491994</td>\n",
              "      <td>2.648607</td>\n",
              "      <td>2.355828</td>\n",
              "      <td>2.921754</td>\n",
              "      <td>2.316953</td>\n",
              "      <td>2.231919</td>\n",
              "      <td>...</td>\n",
              "      <td>2.634353</td>\n",
              "      <td>2.198965</td>\n",
              "      <td>2.246445</td>\n",
              "      <td>2.327131</td>\n",
              "      <td>2.710852</td>\n",
              "      <td>1.971494</td>\n",
              "      <td>1.743328</td>\n",
              "      <td>2.098736</td>\n",
              "      <td>2.921265</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.262845</td>\n",
              "      <td>2.747069</td>\n",
              "      <td>2.666440</td>\n",
              "      <td>2.893101</td>\n",
              "      <td>2.998907</td>\n",
              "      <td>2.992614</td>\n",
              "      <td>2.352489</td>\n",
              "      <td>3.307086</td>\n",
              "      <td>2.165011</td>\n",
              "      <td>1.966337</td>\n",
              "      <td>...</td>\n",
              "      <td>1.876583</td>\n",
              "      <td>1.916729</td>\n",
              "      <td>1.719003</td>\n",
              "      <td>1.774782</td>\n",
              "      <td>2.110986</td>\n",
              "      <td>1.840146</td>\n",
              "      <td>1.904847</td>\n",
              "      <td>1.471070</td>\n",
              "      <td>1.703865</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.239799</td>\n",
              "      <td>2.785209</td>\n",
              "      <td>2.600757</td>\n",
              "      <td>3.116527</td>\n",
              "      <td>2.977250</td>\n",
              "      <td>2.859183</td>\n",
              "      <td>2.296027</td>\n",
              "      <td>3.216666</td>\n",
              "      <td>2.221606</td>\n",
              "      <td>2.424350</td>\n",
              "      <td>...</td>\n",
              "      <td>2.242884</td>\n",
              "      <td>1.939796</td>\n",
              "      <td>1.736053</td>\n",
              "      <td>2.100648</td>\n",
              "      <td>2.456737</td>\n",
              "      <td>2.037821</td>\n",
              "      <td>1.935020</td>\n",
              "      <td>1.968626</td>\n",
              "      <td>2.395988</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 401 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03e1a229-d5d7-4fe1-beb6-eec56dd3292b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03e1a229-d5d7-4fe1-beb6-eec56dd3292b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03e1a229-d5d7-4fe1-beb6-eec56dd3292b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Df_train dengan fitur 3"
      ],
      "metadata": {
        "id": "mCRkFEFdWIft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train3 = df_train[ab3_features]\n",
        "df_train3.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "EgXqkGfMUOMZ",
        "outputId": "deddefed-f03d-407f-faa5-90f1f348a9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   211612_s_at  219678_x_at  217653_x_at  211996_s_at  214594_x_at  \\\n",
              "0     2.433180     2.672850     2.223647     2.894223     2.730180   \n",
              "1     2.261091     2.641439     2.350872     3.042087     2.856150   \n",
              "2     2.385914     2.510368     1.996011     2.624352     2.491994   \n",
              "3     2.262845     2.747069     2.666440     2.893101     2.998907   \n",
              "4     2.239799     2.785209     2.600757     3.116527     2.977250   \n",
              "\n",
              "   218155_x_at  202936_s_at  207730_x_at  205401_at  216609_at  ...  \\\n",
              "0     2.708516     2.677585     3.043026   2.277064   2.318040  ...   \n",
              "1     2.800348     2.392170     3.129235   2.249331   2.306733  ...   \n",
              "2     2.648607     2.355828     2.921754   2.316953   2.231919  ...   \n",
              "3     2.992614     2.352489     3.307086   2.165011   1.966337  ...   \n",
              "4     2.859183     2.296027     3.216666   2.221606   2.424350  ...   \n",
              "\n",
              "   208654_s_at  202131_s_at  202817_s_at  201123_s_at  218002_s_at  \\\n",
              "0     2.940958     2.170559     2.116067     2.485884     2.414447   \n",
              "1     2.875015     2.089126     2.354635     2.642448     2.533421   \n",
              "2     2.710852     1.971494     1.743328     2.171087     2.153860   \n",
              "3     2.110986     1.840146     1.904847     2.203658     2.326658   \n",
              "4     2.456737     2.037821     1.935020     2.410492     3.039731   \n",
              "\n",
              "   211985_s_at  200751_s_at  34031_i_at  201339_s_at  Label  \n",
              "0     3.069618     2.456802    2.136241     2.794302    1.0  \n",
              "1     2.999199     2.582642    2.106757     2.788661    0.0  \n",
              "2     2.891588     2.406262    2.098736     2.921265    1.0  \n",
              "3     1.982301     1.346213    1.471070     1.703865    1.0  \n",
              "4     2.723537     2.164480    1.968626     2.395988    0.0  \n",
              "\n",
              "[5 rows x 501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b64c68a0-a517-4200-8db0-a4d60c6d164b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>211612_s_at</th>\n",
              "      <th>219678_x_at</th>\n",
              "      <th>217653_x_at</th>\n",
              "      <th>211996_s_at</th>\n",
              "      <th>214594_x_at</th>\n",
              "      <th>218155_x_at</th>\n",
              "      <th>202936_s_at</th>\n",
              "      <th>207730_x_at</th>\n",
              "      <th>205401_at</th>\n",
              "      <th>216609_at</th>\n",
              "      <th>...</th>\n",
              "      <th>208654_s_at</th>\n",
              "      <th>202131_s_at</th>\n",
              "      <th>202817_s_at</th>\n",
              "      <th>201123_s_at</th>\n",
              "      <th>218002_s_at</th>\n",
              "      <th>211985_s_at</th>\n",
              "      <th>200751_s_at</th>\n",
              "      <th>34031_i_at</th>\n",
              "      <th>201339_s_at</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.433180</td>\n",
              "      <td>2.672850</td>\n",
              "      <td>2.223647</td>\n",
              "      <td>2.894223</td>\n",
              "      <td>2.730180</td>\n",
              "      <td>2.708516</td>\n",
              "      <td>2.677585</td>\n",
              "      <td>3.043026</td>\n",
              "      <td>2.277064</td>\n",
              "      <td>2.318040</td>\n",
              "      <td>...</td>\n",
              "      <td>2.940958</td>\n",
              "      <td>2.170559</td>\n",
              "      <td>2.116067</td>\n",
              "      <td>2.485884</td>\n",
              "      <td>2.414447</td>\n",
              "      <td>3.069618</td>\n",
              "      <td>2.456802</td>\n",
              "      <td>2.136241</td>\n",
              "      <td>2.794302</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.261091</td>\n",
              "      <td>2.641439</td>\n",
              "      <td>2.350872</td>\n",
              "      <td>3.042087</td>\n",
              "      <td>2.856150</td>\n",
              "      <td>2.800348</td>\n",
              "      <td>2.392170</td>\n",
              "      <td>3.129235</td>\n",
              "      <td>2.249331</td>\n",
              "      <td>2.306733</td>\n",
              "      <td>...</td>\n",
              "      <td>2.875015</td>\n",
              "      <td>2.089126</td>\n",
              "      <td>2.354635</td>\n",
              "      <td>2.642448</td>\n",
              "      <td>2.533421</td>\n",
              "      <td>2.999199</td>\n",
              "      <td>2.582642</td>\n",
              "      <td>2.106757</td>\n",
              "      <td>2.788661</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.385914</td>\n",
              "      <td>2.510368</td>\n",
              "      <td>1.996011</td>\n",
              "      <td>2.624352</td>\n",
              "      <td>2.491994</td>\n",
              "      <td>2.648607</td>\n",
              "      <td>2.355828</td>\n",
              "      <td>2.921754</td>\n",
              "      <td>2.316953</td>\n",
              "      <td>2.231919</td>\n",
              "      <td>...</td>\n",
              "      <td>2.710852</td>\n",
              "      <td>1.971494</td>\n",
              "      <td>1.743328</td>\n",
              "      <td>2.171087</td>\n",
              "      <td>2.153860</td>\n",
              "      <td>2.891588</td>\n",
              "      <td>2.406262</td>\n",
              "      <td>2.098736</td>\n",
              "      <td>2.921265</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.262845</td>\n",
              "      <td>2.747069</td>\n",
              "      <td>2.666440</td>\n",
              "      <td>2.893101</td>\n",
              "      <td>2.998907</td>\n",
              "      <td>2.992614</td>\n",
              "      <td>2.352489</td>\n",
              "      <td>3.307086</td>\n",
              "      <td>2.165011</td>\n",
              "      <td>1.966337</td>\n",
              "      <td>...</td>\n",
              "      <td>2.110986</td>\n",
              "      <td>1.840146</td>\n",
              "      <td>1.904847</td>\n",
              "      <td>2.203658</td>\n",
              "      <td>2.326658</td>\n",
              "      <td>1.982301</td>\n",
              "      <td>1.346213</td>\n",
              "      <td>1.471070</td>\n",
              "      <td>1.703865</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.239799</td>\n",
              "      <td>2.785209</td>\n",
              "      <td>2.600757</td>\n",
              "      <td>3.116527</td>\n",
              "      <td>2.977250</td>\n",
              "      <td>2.859183</td>\n",
              "      <td>2.296027</td>\n",
              "      <td>3.216666</td>\n",
              "      <td>2.221606</td>\n",
              "      <td>2.424350</td>\n",
              "      <td>...</td>\n",
              "      <td>2.456737</td>\n",
              "      <td>2.037821</td>\n",
              "      <td>1.935020</td>\n",
              "      <td>2.410492</td>\n",
              "      <td>3.039731</td>\n",
              "      <td>2.723537</td>\n",
              "      <td>2.164480</td>\n",
              "      <td>1.968626</td>\n",
              "      <td>2.395988</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 501 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b64c68a0-a517-4200-8db0-a4d60c6d164b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b64c68a0-a517-4200-8db0-a4d60c6d164b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b64c68a0-a517-4200-8db0-a4d60c6d164b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## X_train dan y_train"
      ],
      "metadata": {
        "id": "nhuiaiHXTAdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X1_train = df_train1.iloc[:,:-1]\n",
        "X1_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "s6r31lIXuzKA",
        "outputId": "872b79d2-377d-4885-ec8a-7a53c5d5f2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   219678_x_at  217653_x_at  211996_s_at  214594_x_at  218155_x_at  \\\n",
              "0     2.672850     2.223647     2.894223     2.730180     2.708516   \n",
              "1     2.641439     2.350872     3.042087     2.856150     2.800348   \n",
              "2     2.510368     1.996011     2.624352     2.491994     2.648607   \n",
              "3     2.747069     2.666440     2.893101     2.998907     2.992614   \n",
              "4     2.785209     2.600757     3.116527     2.977250     2.859183   \n",
              "\n",
              "   207730_x_at  216609_at  207953_at  217679_x_at  210168_at  ...  \\\n",
              "0     3.043026   2.318040   2.462324     2.748249   2.698125  ...   \n",
              "1     3.129235   2.306733   2.476773     2.884853   2.293900  ...   \n",
              "2     2.921754   2.231919   2.371051     2.482992   2.399431  ...   \n",
              "3     3.307086   1.966337   2.863540     3.172937   2.521457  ...   \n",
              "4     3.216666   2.424350   2.650209     2.929251   2.155440  ...   \n",
              "\n",
              "   208750_s_at  206544_x_at  200598_s_at  212515_s_at  213872_at  202435_s_at  \\\n",
              "0     2.621121     2.584677     2.614547     2.459196   2.371555     1.859862   \n",
              "1     2.720216     2.541014     2.464834     2.651054   2.249695     1.991560   \n",
              "2     2.426039     2.408422     2.665663     2.371579   2.046329     2.353558   \n",
              "3     2.179337     2.314931     2.019661     2.192755   2.209179     1.973821   \n",
              "4     2.357678     2.305571     2.192273     2.404168   2.183277     2.610495   \n",
              "\n",
              "   211505_s_at  40665_at  208654_s_at  202817_s_at  \n",
              "0     2.449663  2.464299     2.940958     2.116067  \n",
              "1     2.262768  2.172416     2.875015     2.354635  \n",
              "2     2.198965  2.246445     2.710852     1.743328  \n",
              "3     1.916729  1.719003     2.110986     1.904847  \n",
              "4     1.939796  1.736053     2.456737     1.935020  \n",
              "\n",
              "[5 rows x 200 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-424df8e2-61f4-48c6-9463-c0bd20158618\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>219678_x_at</th>\n",
              "      <th>217653_x_at</th>\n",
              "      <th>211996_s_at</th>\n",
              "      <th>214594_x_at</th>\n",
              "      <th>218155_x_at</th>\n",
              "      <th>207730_x_at</th>\n",
              "      <th>216609_at</th>\n",
              "      <th>207953_at</th>\n",
              "      <th>217679_x_at</th>\n",
              "      <th>210168_at</th>\n",
              "      <th>...</th>\n",
              "      <th>208750_s_at</th>\n",
              "      <th>206544_x_at</th>\n",
              "      <th>200598_s_at</th>\n",
              "      <th>212515_s_at</th>\n",
              "      <th>213872_at</th>\n",
              "      <th>202435_s_at</th>\n",
              "      <th>211505_s_at</th>\n",
              "      <th>40665_at</th>\n",
              "      <th>208654_s_at</th>\n",
              "      <th>202817_s_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.672850</td>\n",
              "      <td>2.223647</td>\n",
              "      <td>2.894223</td>\n",
              "      <td>2.730180</td>\n",
              "      <td>2.708516</td>\n",
              "      <td>3.043026</td>\n",
              "      <td>2.318040</td>\n",
              "      <td>2.462324</td>\n",
              "      <td>2.748249</td>\n",
              "      <td>2.698125</td>\n",
              "      <td>...</td>\n",
              "      <td>2.621121</td>\n",
              "      <td>2.584677</td>\n",
              "      <td>2.614547</td>\n",
              "      <td>2.459196</td>\n",
              "      <td>2.371555</td>\n",
              "      <td>1.859862</td>\n",
              "      <td>2.449663</td>\n",
              "      <td>2.464299</td>\n",
              "      <td>2.940958</td>\n",
              "      <td>2.116067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.641439</td>\n",
              "      <td>2.350872</td>\n",
              "      <td>3.042087</td>\n",
              "      <td>2.856150</td>\n",
              "      <td>2.800348</td>\n",
              "      <td>3.129235</td>\n",
              "      <td>2.306733</td>\n",
              "      <td>2.476773</td>\n",
              "      <td>2.884853</td>\n",
              "      <td>2.293900</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720216</td>\n",
              "      <td>2.541014</td>\n",
              "      <td>2.464834</td>\n",
              "      <td>2.651054</td>\n",
              "      <td>2.249695</td>\n",
              "      <td>1.991560</td>\n",
              "      <td>2.262768</td>\n",
              "      <td>2.172416</td>\n",
              "      <td>2.875015</td>\n",
              "      <td>2.354635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.510368</td>\n",
              "      <td>1.996011</td>\n",
              "      <td>2.624352</td>\n",
              "      <td>2.491994</td>\n",
              "      <td>2.648607</td>\n",
              "      <td>2.921754</td>\n",
              "      <td>2.231919</td>\n",
              "      <td>2.371051</td>\n",
              "      <td>2.482992</td>\n",
              "      <td>2.399431</td>\n",
              "      <td>...</td>\n",
              "      <td>2.426039</td>\n",
              "      <td>2.408422</td>\n",
              "      <td>2.665663</td>\n",
              "      <td>2.371579</td>\n",
              "      <td>2.046329</td>\n",
              "      <td>2.353558</td>\n",
              "      <td>2.198965</td>\n",
              "      <td>2.246445</td>\n",
              "      <td>2.710852</td>\n",
              "      <td>1.743328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.747069</td>\n",
              "      <td>2.666440</td>\n",
              "      <td>2.893101</td>\n",
              "      <td>2.998907</td>\n",
              "      <td>2.992614</td>\n",
              "      <td>3.307086</td>\n",
              "      <td>1.966337</td>\n",
              "      <td>2.863540</td>\n",
              "      <td>3.172937</td>\n",
              "      <td>2.521457</td>\n",
              "      <td>...</td>\n",
              "      <td>2.179337</td>\n",
              "      <td>2.314931</td>\n",
              "      <td>2.019661</td>\n",
              "      <td>2.192755</td>\n",
              "      <td>2.209179</td>\n",
              "      <td>1.973821</td>\n",
              "      <td>1.916729</td>\n",
              "      <td>1.719003</td>\n",
              "      <td>2.110986</td>\n",
              "      <td>1.904847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.785209</td>\n",
              "      <td>2.600757</td>\n",
              "      <td>3.116527</td>\n",
              "      <td>2.977250</td>\n",
              "      <td>2.859183</td>\n",
              "      <td>3.216666</td>\n",
              "      <td>2.424350</td>\n",
              "      <td>2.650209</td>\n",
              "      <td>2.929251</td>\n",
              "      <td>2.155440</td>\n",
              "      <td>...</td>\n",
              "      <td>2.357678</td>\n",
              "      <td>2.305571</td>\n",
              "      <td>2.192273</td>\n",
              "      <td>2.404168</td>\n",
              "      <td>2.183277</td>\n",
              "      <td>2.610495</td>\n",
              "      <td>1.939796</td>\n",
              "      <td>1.736053</td>\n",
              "      <td>2.456737</td>\n",
              "      <td>1.935020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 200 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-424df8e2-61f4-48c6-9463-c0bd20158618')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-424df8e2-61f4-48c6-9463-c0bd20158618 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-424df8e2-61f4-48c6-9463-c0bd20158618');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y1_train = df_train1.iloc[:,-1]\n",
        "y1_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "137hMO2TvTum",
        "outputId": "edbeab07-51fd-4034-dff9-8eb165da5613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    0.0\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2_train = df_train2.iloc[:,:-1]\n",
        "X2_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f0350bb3-5f93-4b0b-9521-58d964287b68",
        "id": "0RdvwhWFWUgr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   211612_s_at  219678_x_at  217653_x_at  211996_s_at  214594_x_at  \\\n",
              "0     2.433180     2.672850     2.223647     2.894223     2.730180   \n",
              "1     2.261091     2.641439     2.350872     3.042087     2.856150   \n",
              "2     2.385914     2.510368     1.996011     2.624352     2.491994   \n",
              "3     2.262845     2.747069     2.666440     2.893101     2.998907   \n",
              "4     2.239799     2.785209     2.600757     3.116527     2.977250   \n",
              "\n",
              "   218155_x_at  202936_s_at  207730_x_at  205401_at  216609_at  ...  \\\n",
              "0     2.708516     2.677585     3.043026   2.277064   2.318040  ...   \n",
              "1     2.800348     2.392170     3.129235   2.249331   2.306733  ...   \n",
              "2     2.648607     2.355828     2.921754   2.316953   2.231919  ...   \n",
              "3     2.992614     2.352489     3.307086   2.165011   1.966337  ...   \n",
              "4     2.859183     2.296027     3.216666   2.221606   2.424350  ...   \n",
              "\n",
              "   205749_at  208671_at  211505_s_at  40665_at  214830_at  208654_s_at  \\\n",
              "0   2.383935   2.547195     2.449663  2.464299   2.316326     2.940958   \n",
              "1   2.435408   2.535646     2.262768  2.172416   2.248017     2.875015   \n",
              "2   2.524147   2.634353     2.198965  2.246445   2.327131     2.710852   \n",
              "3   2.558272   1.876583     1.916729  1.719003   1.774782     2.110986   \n",
              "4   3.102548   2.242884     1.939796  1.736053   2.100648     2.456737   \n",
              "\n",
              "   202131_s_at  202817_s_at  34031_i_at  201339_s_at  \n",
              "0     2.170559     2.116067    2.136241     2.794302  \n",
              "1     2.089126     2.354635    2.106757     2.788661  \n",
              "2     1.971494     1.743328    2.098736     2.921265  \n",
              "3     1.840146     1.904847    1.471070     1.703865  \n",
              "4     2.037821     1.935020    1.968626     2.395988  \n",
              "\n",
              "[5 rows x 400 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d85229ba-1f8c-415f-aae7-b7854db4f20a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>211612_s_at</th>\n",
              "      <th>219678_x_at</th>\n",
              "      <th>217653_x_at</th>\n",
              "      <th>211996_s_at</th>\n",
              "      <th>214594_x_at</th>\n",
              "      <th>218155_x_at</th>\n",
              "      <th>202936_s_at</th>\n",
              "      <th>207730_x_at</th>\n",
              "      <th>205401_at</th>\n",
              "      <th>216609_at</th>\n",
              "      <th>...</th>\n",
              "      <th>205749_at</th>\n",
              "      <th>208671_at</th>\n",
              "      <th>211505_s_at</th>\n",
              "      <th>40665_at</th>\n",
              "      <th>214830_at</th>\n",
              "      <th>208654_s_at</th>\n",
              "      <th>202131_s_at</th>\n",
              "      <th>202817_s_at</th>\n",
              "      <th>34031_i_at</th>\n",
              "      <th>201339_s_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.433180</td>\n",
              "      <td>2.672850</td>\n",
              "      <td>2.223647</td>\n",
              "      <td>2.894223</td>\n",
              "      <td>2.730180</td>\n",
              "      <td>2.708516</td>\n",
              "      <td>2.677585</td>\n",
              "      <td>3.043026</td>\n",
              "      <td>2.277064</td>\n",
              "      <td>2.318040</td>\n",
              "      <td>...</td>\n",
              "      <td>2.383935</td>\n",
              "      <td>2.547195</td>\n",
              "      <td>2.449663</td>\n",
              "      <td>2.464299</td>\n",
              "      <td>2.316326</td>\n",
              "      <td>2.940958</td>\n",
              "      <td>2.170559</td>\n",
              "      <td>2.116067</td>\n",
              "      <td>2.136241</td>\n",
              "      <td>2.794302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.261091</td>\n",
              "      <td>2.641439</td>\n",
              "      <td>2.350872</td>\n",
              "      <td>3.042087</td>\n",
              "      <td>2.856150</td>\n",
              "      <td>2.800348</td>\n",
              "      <td>2.392170</td>\n",
              "      <td>3.129235</td>\n",
              "      <td>2.249331</td>\n",
              "      <td>2.306733</td>\n",
              "      <td>...</td>\n",
              "      <td>2.435408</td>\n",
              "      <td>2.535646</td>\n",
              "      <td>2.262768</td>\n",
              "      <td>2.172416</td>\n",
              "      <td>2.248017</td>\n",
              "      <td>2.875015</td>\n",
              "      <td>2.089126</td>\n",
              "      <td>2.354635</td>\n",
              "      <td>2.106757</td>\n",
              "      <td>2.788661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.385914</td>\n",
              "      <td>2.510368</td>\n",
              "      <td>1.996011</td>\n",
              "      <td>2.624352</td>\n",
              "      <td>2.491994</td>\n",
              "      <td>2.648607</td>\n",
              "      <td>2.355828</td>\n",
              "      <td>2.921754</td>\n",
              "      <td>2.316953</td>\n",
              "      <td>2.231919</td>\n",
              "      <td>...</td>\n",
              "      <td>2.524147</td>\n",
              "      <td>2.634353</td>\n",
              "      <td>2.198965</td>\n",
              "      <td>2.246445</td>\n",
              "      <td>2.327131</td>\n",
              "      <td>2.710852</td>\n",
              "      <td>1.971494</td>\n",
              "      <td>1.743328</td>\n",
              "      <td>2.098736</td>\n",
              "      <td>2.921265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.262845</td>\n",
              "      <td>2.747069</td>\n",
              "      <td>2.666440</td>\n",
              "      <td>2.893101</td>\n",
              "      <td>2.998907</td>\n",
              "      <td>2.992614</td>\n",
              "      <td>2.352489</td>\n",
              "      <td>3.307086</td>\n",
              "      <td>2.165011</td>\n",
              "      <td>1.966337</td>\n",
              "      <td>...</td>\n",
              "      <td>2.558272</td>\n",
              "      <td>1.876583</td>\n",
              "      <td>1.916729</td>\n",
              "      <td>1.719003</td>\n",
              "      <td>1.774782</td>\n",
              "      <td>2.110986</td>\n",
              "      <td>1.840146</td>\n",
              "      <td>1.904847</td>\n",
              "      <td>1.471070</td>\n",
              "      <td>1.703865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.239799</td>\n",
              "      <td>2.785209</td>\n",
              "      <td>2.600757</td>\n",
              "      <td>3.116527</td>\n",
              "      <td>2.977250</td>\n",
              "      <td>2.859183</td>\n",
              "      <td>2.296027</td>\n",
              "      <td>3.216666</td>\n",
              "      <td>2.221606</td>\n",
              "      <td>2.424350</td>\n",
              "      <td>...</td>\n",
              "      <td>3.102548</td>\n",
              "      <td>2.242884</td>\n",
              "      <td>1.939796</td>\n",
              "      <td>1.736053</td>\n",
              "      <td>2.100648</td>\n",
              "      <td>2.456737</td>\n",
              "      <td>2.037821</td>\n",
              "      <td>1.935020</td>\n",
              "      <td>1.968626</td>\n",
              "      <td>2.395988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 400 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d85229ba-1f8c-415f-aae7-b7854db4f20a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d85229ba-1f8c-415f-aae7-b7854db4f20a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d85229ba-1f8c-415f-aae7-b7854db4f20a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y2_train = df_train2.iloc[:,-1]\n",
        "y2_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdf3a36-9601-433f-ee46-f2b7aa659db5",
        "id": "b6jWoPq3WUgt"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    0.0\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X3_train = df_train3.iloc[:,:-1]\n",
        "X3_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "2dfd8188-9323-416a-cb78-585a2ce51eb4",
        "id": "QyMhT8npWU8D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   211612_s_at  219678_x_at  217653_x_at  211996_s_at  214594_x_at  \\\n",
              "0     2.433180     2.672850     2.223647     2.894223     2.730180   \n",
              "1     2.261091     2.641439     2.350872     3.042087     2.856150   \n",
              "2     2.385914     2.510368     1.996011     2.624352     2.491994   \n",
              "3     2.262845     2.747069     2.666440     2.893101     2.998907   \n",
              "4     2.239799     2.785209     2.600757     3.116527     2.977250   \n",
              "\n",
              "   218155_x_at  202936_s_at  207730_x_at  205401_at  216609_at  ...  \\\n",
              "0     2.708516     2.677585     3.043026   2.277064   2.318040  ...   \n",
              "1     2.800348     2.392170     3.129235   2.249331   2.306733  ...   \n",
              "2     2.648607     2.355828     2.921754   2.316953   2.231919  ...   \n",
              "3     2.992614     2.352489     3.307086   2.165011   1.966337  ...   \n",
              "4     2.859183     2.296027     3.216666   2.221606   2.424350  ...   \n",
              "\n",
              "   214830_at  208654_s_at  202131_s_at  202817_s_at  201123_s_at  218002_s_at  \\\n",
              "0   2.316326     2.940958     2.170559     2.116067     2.485884     2.414447   \n",
              "1   2.248017     2.875015     2.089126     2.354635     2.642448     2.533421   \n",
              "2   2.327131     2.710852     1.971494     1.743328     2.171087     2.153860   \n",
              "3   1.774782     2.110986     1.840146     1.904847     2.203658     2.326658   \n",
              "4   2.100648     2.456737     2.037821     1.935020     2.410492     3.039731   \n",
              "\n",
              "   211985_s_at  200751_s_at  34031_i_at  201339_s_at  \n",
              "0     3.069618     2.456802    2.136241     2.794302  \n",
              "1     2.999199     2.582642    2.106757     2.788661  \n",
              "2     2.891588     2.406262    2.098736     2.921265  \n",
              "3     1.982301     1.346213    1.471070     1.703865  \n",
              "4     2.723537     2.164480    1.968626     2.395988  \n",
              "\n",
              "[5 rows x 500 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38115d94-3802-4d7a-97e8-4f88517ccc21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>211612_s_at</th>\n",
              "      <th>219678_x_at</th>\n",
              "      <th>217653_x_at</th>\n",
              "      <th>211996_s_at</th>\n",
              "      <th>214594_x_at</th>\n",
              "      <th>218155_x_at</th>\n",
              "      <th>202936_s_at</th>\n",
              "      <th>207730_x_at</th>\n",
              "      <th>205401_at</th>\n",
              "      <th>216609_at</th>\n",
              "      <th>...</th>\n",
              "      <th>214830_at</th>\n",
              "      <th>208654_s_at</th>\n",
              "      <th>202131_s_at</th>\n",
              "      <th>202817_s_at</th>\n",
              "      <th>201123_s_at</th>\n",
              "      <th>218002_s_at</th>\n",
              "      <th>211985_s_at</th>\n",
              "      <th>200751_s_at</th>\n",
              "      <th>34031_i_at</th>\n",
              "      <th>201339_s_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.433180</td>\n",
              "      <td>2.672850</td>\n",
              "      <td>2.223647</td>\n",
              "      <td>2.894223</td>\n",
              "      <td>2.730180</td>\n",
              "      <td>2.708516</td>\n",
              "      <td>2.677585</td>\n",
              "      <td>3.043026</td>\n",
              "      <td>2.277064</td>\n",
              "      <td>2.318040</td>\n",
              "      <td>...</td>\n",
              "      <td>2.316326</td>\n",
              "      <td>2.940958</td>\n",
              "      <td>2.170559</td>\n",
              "      <td>2.116067</td>\n",
              "      <td>2.485884</td>\n",
              "      <td>2.414447</td>\n",
              "      <td>3.069618</td>\n",
              "      <td>2.456802</td>\n",
              "      <td>2.136241</td>\n",
              "      <td>2.794302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.261091</td>\n",
              "      <td>2.641439</td>\n",
              "      <td>2.350872</td>\n",
              "      <td>3.042087</td>\n",
              "      <td>2.856150</td>\n",
              "      <td>2.800348</td>\n",
              "      <td>2.392170</td>\n",
              "      <td>3.129235</td>\n",
              "      <td>2.249331</td>\n",
              "      <td>2.306733</td>\n",
              "      <td>...</td>\n",
              "      <td>2.248017</td>\n",
              "      <td>2.875015</td>\n",
              "      <td>2.089126</td>\n",
              "      <td>2.354635</td>\n",
              "      <td>2.642448</td>\n",
              "      <td>2.533421</td>\n",
              "      <td>2.999199</td>\n",
              "      <td>2.582642</td>\n",
              "      <td>2.106757</td>\n",
              "      <td>2.788661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.385914</td>\n",
              "      <td>2.510368</td>\n",
              "      <td>1.996011</td>\n",
              "      <td>2.624352</td>\n",
              "      <td>2.491994</td>\n",
              "      <td>2.648607</td>\n",
              "      <td>2.355828</td>\n",
              "      <td>2.921754</td>\n",
              "      <td>2.316953</td>\n",
              "      <td>2.231919</td>\n",
              "      <td>...</td>\n",
              "      <td>2.327131</td>\n",
              "      <td>2.710852</td>\n",
              "      <td>1.971494</td>\n",
              "      <td>1.743328</td>\n",
              "      <td>2.171087</td>\n",
              "      <td>2.153860</td>\n",
              "      <td>2.891588</td>\n",
              "      <td>2.406262</td>\n",
              "      <td>2.098736</td>\n",
              "      <td>2.921265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.262845</td>\n",
              "      <td>2.747069</td>\n",
              "      <td>2.666440</td>\n",
              "      <td>2.893101</td>\n",
              "      <td>2.998907</td>\n",
              "      <td>2.992614</td>\n",
              "      <td>2.352489</td>\n",
              "      <td>3.307086</td>\n",
              "      <td>2.165011</td>\n",
              "      <td>1.966337</td>\n",
              "      <td>...</td>\n",
              "      <td>1.774782</td>\n",
              "      <td>2.110986</td>\n",
              "      <td>1.840146</td>\n",
              "      <td>1.904847</td>\n",
              "      <td>2.203658</td>\n",
              "      <td>2.326658</td>\n",
              "      <td>1.982301</td>\n",
              "      <td>1.346213</td>\n",
              "      <td>1.471070</td>\n",
              "      <td>1.703865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.239799</td>\n",
              "      <td>2.785209</td>\n",
              "      <td>2.600757</td>\n",
              "      <td>3.116527</td>\n",
              "      <td>2.977250</td>\n",
              "      <td>2.859183</td>\n",
              "      <td>2.296027</td>\n",
              "      <td>3.216666</td>\n",
              "      <td>2.221606</td>\n",
              "      <td>2.424350</td>\n",
              "      <td>...</td>\n",
              "      <td>2.100648</td>\n",
              "      <td>2.456737</td>\n",
              "      <td>2.037821</td>\n",
              "      <td>1.935020</td>\n",
              "      <td>2.410492</td>\n",
              "      <td>3.039731</td>\n",
              "      <td>2.723537</td>\n",
              "      <td>2.164480</td>\n",
              "      <td>1.968626</td>\n",
              "      <td>2.395988</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38115d94-3802-4d7a-97e8-4f88517ccc21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38115d94-3802-4d7a-97e8-4f88517ccc21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38115d94-3802-4d7a-97e8-4f88517ccc21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y3_train = df_train3.iloc[:,-1]\n",
        "y3_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ac2aa6-8f29-4501-886f-c1548b40d639",
        "id": "qRlqj7hCWU8G"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    0.0\n",
              "Name: Label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model tanpa Tuning"
      ],
      "metadata": {
        "id": "9t0AjQ1OTEPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AB1"
      ],
      "metadata": {
        "id": "2SgleqWJTzpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab1_non_tuning = AdaBoostClassifier()\n",
        "ab1_non_tuning_acc = cross_val_score(ab1_non_tuning, X1_train, y1_train, scoring=\"accuracy\", cv=10)\n",
        "print(\"Akurasi masing-masing = \", ab1_non_tuning_acc)\n",
        "print(\"Rata-rata = \", ab1_non_tuning_acc.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQGu2RBYSqkk",
        "outputId": "200789ea-950c-4638-da8a-d728a0bfb6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi masing-masing =  [0.61538462 0.61538462 0.76923077 0.84615385 0.76923077 0.76923077\n",
            " 0.84615385 0.76923077 0.61538462 0.76923077]\n",
            "Rata-rata =  0.7384615384615384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AB2"
      ],
      "metadata": {
        "id": "D_kUApnTWyHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab2_non_tuning = AdaBoostClassifier()\n",
        "ab2_non_tuning_acc = cross_val_score(ab2_non_tuning, X2_train, y2_train, scoring=\"accuracy\", cv=10)\n",
        "print(\"Akurasi masing-masing = \", ab2_non_tuning_acc)\n",
        "print(\"Rata-rata = \", ab2_non_tuning_acc.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c9e0a3-8765-4acb-ac3e-b6af52564773",
        "id": "flv6B01AWyHX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi masing-masing =  [0.84615385 0.69230769 0.61538462 0.84615385 0.76923077 0.69230769\n",
            " 0.84615385 0.84615385 0.69230769 0.76923077]\n",
            "Rata-rata =  0.7615384615384616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AB3"
      ],
      "metadata": {
        "id": "cMbfyBjXWyVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab3_non_tuning = AdaBoostClassifier()\n",
        "ab3_non_tuning_acc = cross_val_score(ab3_non_tuning, X3_train, y3_train, scoring=\"accuracy\", cv=10)\n",
        "print(\"Akurasi masing-masing = \", ab3_non_tuning_acc)\n",
        "print(\"Rata-rata = \", ab3_non_tuning_acc.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1c5ba7-e2f3-4a1e-e3eb-3b8fd63d9401",
        "id": "jeZjyWZ_WyV0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi masing-masing =  [0.61538462 0.76923077 0.92307692 0.92307692 0.84615385 0.61538462\n",
            " 0.76923077 0.84615385 0.61538462 0.76923077]\n",
            "Rata-rata =  0.7692307692307693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "amnNy2SywM6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameter yang akan dituning"
      ],
      "metadata": {
        "id": "5lxRbubebJys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisi Parameter"
      ],
      "metadata": {
        "id": "bslIe0zJB5vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_ab = {\n",
        "        'n_estimators' : [50, 100, 150, 200],\n",
        "        'learning_rate' : [0.01, 0.1, 1]  \n",
        "        }"
      ],
      "metadata": {
        "id": "_ZNmqByNbIBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AB1"
      ],
      "metadata": {
        "id": "_bgMkX0UyGX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab1_tuning = AdaBoostClassifier()"
      ],
      "metadata": {
        "id": "NJUjikkrwWzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gridsearch (sekitar 3 menit running)"
      ],
      "metadata": {
        "id": "naCkGh7mXwmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_ab1 = GridSearchCV(ab1_tuning,\n",
        "                        parameters_ab,\n",
        "                        scoring='accuracy',\n",
        "                        cv = 10,\n",
        "                        verbose=3)\n",
        "search_ab1.fit(X1_train, y1_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzXuSNLcyvBT",
        "outputId": "1f7a886e-2ab6-4139-ed8b-02afb273f747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.2s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=50;, score=0.692 total time=   0.2s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=50;, score=0.615 total time=   0.2s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=50;, score=0.846 total time=   0.2s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=50;, score=0.615 total time=   0.2s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.2s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=50;, score=0.462 total time=   0.2s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=50;, score=0.846 total time=   0.2s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.2s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=50;, score=0.692 total time=   0.2s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.5s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=100;, score=0.615 total time=   0.5s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.5s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=100;, score=0.846 total time=   0.4s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=100;, score=0.615 total time=   0.4s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.5s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=100;, score=0.615 total time=   0.5s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=100;, score=0.846 total time=   0.5s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.5s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=100;, score=0.846 total time=   0.5s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   0.7s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=150;, score=0.692 total time=   0.7s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   0.7s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=150;, score=0.846 total time=   0.7s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=150;, score=0.692 total time=   0.7s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=150;, score=0.538 total time=   0.6s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=150;, score=0.769 total time=   0.6s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=150;, score=0.846 total time=   0.7s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=150;, score=0.692 total time=   0.7s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=150;, score=0.846 total time=   0.7s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=200;, score=0.538 total time=   0.9s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   0.9s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=200;, score=0.615 total time=   0.9s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=200;, score=0.846 total time=   0.9s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   1.0s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=200;, score=0.538 total time=   0.9s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   0.9s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=200;, score=0.846 total time=   0.9s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   0.8s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   0.8s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=50;, score=0.692 total time=   0.2s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=50;, score=0.692 total time=   0.2s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=50;, score=0.538 total time=   0.2s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.2s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=50;, score=0.769 total time=   0.2s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=50;, score=0.692 total time=   0.2s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.2s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=50;, score=0.923 total time=   0.2s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=50;, score=0.692 total time=   0.2s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=50;, score=0.923 total time=   0.2s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.4s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=100;, score=0.769 total time=   0.4s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=100;, score=0.615 total time=   0.4s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   0.4s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=100;, score=0.769 total time=   0.4s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   0.4s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.4s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=100;, score=0.923 total time=   0.5s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=100;, score=0.615 total time=   0.5s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=100;, score=0.923 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   0.6s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=150;, score=0.769 total time=   0.6s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   0.6s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=150;, score=0.923 total time=   0.6s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=150;, score=0.769 total time=   0.7s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=150;, score=0.769 total time=   0.6s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   0.6s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   0.6s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=150;, score=0.615 total time=   0.7s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   0.7s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   0.9s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   0.9s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=200;, score=0.615 total time=   0.9s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=200;, score=0.923 total time=   0.9s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   0.9s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=200;, score=0.692 total time=   0.9s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=200;, score=0.692 total time=   0.8s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   0.8s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=200;, score=0.615 total time=   0.8s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   0.8s\n",
            "[CV 1/10] END .learning_rate=1, n_estimators=50;, score=0.615 total time=   0.2s\n",
            "[CV 2/10] END .learning_rate=1, n_estimators=50;, score=0.615 total time=   0.2s\n",
            "[CV 3/10] END .learning_rate=1, n_estimators=50;, score=0.769 total time=   0.2s\n",
            "[CV 4/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.2s\n",
            "[CV 5/10] END .learning_rate=1, n_estimators=50;, score=0.769 total time=   0.2s\n",
            "[CV 6/10] END .learning_rate=1, n_estimators=50;, score=0.769 total time=   0.2s\n",
            "[CV 7/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.2s\n",
            "[CV 8/10] END .learning_rate=1, n_estimators=50;, score=0.769 total time=   0.2s\n",
            "[CV 9/10] END .learning_rate=1, n_estimators=50;, score=0.615 total time=   0.2s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=50;, score=0.769 total time=   0.2s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=100;, score=0.692 total time=   0.4s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.4s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.5s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=100;, score=0.923 total time=   0.4s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.4s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.5s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.5s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=100;, score=0.846 total time=   0.5s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=100;, score=0.615 total time=   0.4s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=150;, score=0.692 total time=   0.7s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   0.7s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   0.6s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   0.7s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   0.7s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   0.7s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   0.6s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=150;, score=0.923 total time=   1.3s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=150;, score=0.692 total time=   1.3s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.3s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=200;, score=0.692 total time=   0.8s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   0.9s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=200;, score=0.692 total time=   0.9s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   0.9s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=200;, score=0.846 total time=   0.9s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=200;, score=0.692 total time=   0.9s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   0.9s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=200;, score=0.923 total time=   0.8s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=200;, score=0.692 total time=   0.9s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=200;, score=0.692 total time=   0.9s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, estimator=AdaBoostClassifier(),\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'n_estimators': [50, 100, 150, 200]},\n",
              "             scoring='accuracy', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akurasi dan parameter terbaik pada Gridsearch"
      ],
      "metadata": {
        "id": "McQVtTyKC1Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab1_best_acc_score = search_ab1.best_score_\n",
        "ab1_best_parameter = search_ab1.best_params_\n",
        "print(\"Akurasi terbaik = \", ab1_best_acc_score)\n",
        "print(\"Parameter terbaik = \", ab1_best_parameter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "970IBo6giwoz",
        "outputId": "bd6c1033-e109-4af9-a9cd-728a1a1796c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi terbaik =  0.7923076923076924\n",
            "Parameter terbaik =  {'learning_rate': 1, 'n_estimators': 150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat model dengan parameter terbaik"
      ],
      "metadata": {
        "id": "Uzv1rPp6C4ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = ab1_best_parameter[\"learning_rate\"]\n",
        "n_estimators = ab1_best_parameter[\"n_estimators\"]\n",
        "\n",
        "ab1_tuning = AdaBoostClassifier(learning_rate=learning_rate, n_estimators=n_estimators)"
      ],
      "metadata": {
        "id": "TgQ8UW5g92Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross val akhir"
      ],
      "metadata": {
        "id": "Xvp6w71VC6iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab1_tuning_acc = cross_val_score(ab1_tuning, X1_train, y1_train, scoring=\"accuracy\", cv=10)\n",
        "print(\"Akurasi masing-masing = \", ab1_tuning_acc)\n",
        "print(\"Rata-rata = \", ab1_tuning_acc.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxZksZFeYPNl",
        "outputId": "19078e37-8d84-41f0-8505-9234cef2e8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi masing-masing =  [0.69230769 0.76923077 0.84615385 0.84615385 0.84615385 0.76923077\n",
            " 0.76923077 0.92307692 0.69230769 0.76923077]\n",
            "Rata-rata =  0.7923076923076924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AB2"
      ],
      "metadata": {
        "id": "lxz4DN8ga1Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab2_tuning = AdaBoostClassifier()"
      ],
      "metadata": {
        "id": "Bdqn4f1Xa1Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gridsearch (sekitar 3 menit running)"
      ],
      "metadata": {
        "id": "yZzOoZpOa1Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_ab2 = GridSearchCV(ab2_tuning,\n",
        "                        parameters_ab,\n",
        "                        scoring='accuracy',\n",
        "                        cv = 10,\n",
        "                        verbose=3)\n",
        "search_ab2.fit(X2_train, y2_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d86e15-8f6d-4f0d-9d93-9fcafc940183",
        "id": "uFBsIwRna1Vc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=50;, score=0.462 total time=   0.4s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.4s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.4s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=100;, score=0.615 total time=   0.7s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=100;, score=0.846 total time=   0.7s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.7s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=100;, score=0.846 total time=   0.7s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=100;, score=0.692 total time=   0.7s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.7s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=100;, score=0.615 total time=   0.7s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.7s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   1.0s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=150;, score=0.846 total time=   1.0s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=150;, score=0.538 total time=   1.0s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=150;, score=0.846 total time=   1.0s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=150;, score=0.769 total time=   1.0s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   1.0s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=150;, score=0.692 total time=   1.0s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=150;, score=0.769 total time=   1.0s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   1.0s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=150;, score=1.000 total time=   1.0s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=200;, score=0.615 total time=   1.4s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=200;, score=0.846 total time=   1.4s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=200;, score=0.538 total time=   1.4s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=200;, score=0.615 total time=   1.4s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   1.4s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   1.4s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=200;, score=0.923 total time=   1.4s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.7s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=100;, score=0.615 total time=   0.7s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   0.7s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   0.7s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   0.7s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.7s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   1.1s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   1.0s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=150;, score=0.615 total time=   1.1s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.1s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.0s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=150;, score=0.769 total time=   1.0s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.0s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=150;, score=0.923 total time=   1.0s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   1.0s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.0s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=200;, score=0.692 total time=   1.4s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=200;, score=0.692 total time=   1.4s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=200;, score=0.615 total time=   1.6s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   1.3s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   1.4s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.3s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=200;, score=0.615 total time=   1.4s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 1/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 2/10] END .learning_rate=1, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 3/10] END .learning_rate=1, n_estimators=50;, score=0.615 total time=   0.3s\n",
            "[CV 4/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.3s\n",
            "[CV 5/10] END .learning_rate=1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 6/10] END .learning_rate=1, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 7/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 8/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 9/10] END .learning_rate=1, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=100;, score=0.846 total time=   0.7s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=100;, score=0.615 total time=   0.7s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=100;, score=0.846 total time=   0.7s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.7s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=100;, score=0.692 total time=   0.7s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=150;, score=0.692 total time=   1.0s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=150;, score=0.692 total time=   1.0s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.2s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.9s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   2.1s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=150;, score=0.692 total time=   1.6s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.0s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.1s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=150;, score=0.692 total time=   1.0s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.1s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.5s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=200;, score=0.846 total time=   1.4s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.3s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=200;, score=0.615 total time=   1.4s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.4s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=200;, score=0.615 total time=   1.4s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.5s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, estimator=AdaBoostClassifier(),\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'n_estimators': [50, 100, 150, 200]},\n",
              "             scoring='accuracy', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akurasi dan parameter terbaik pada Gridsearh"
      ],
      "metadata": {
        "id": "nxTAzAU6C8xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab2_best_acc_score = search_ab2.best_score_\n",
        "ab2_best_parameter = search_ab2.best_params_\n",
        "print(\"Akurasi terbaik = \", ab2_best_acc_score)\n",
        "print(\"Parameter terbaik = \", ab2_best_parameter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3286f2e-ee04-496e-831f-dcd11ed8edc7",
        "id": "-gQObjwXa1Vc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi terbaik =  0.7769230769230769\n",
            "Parameter terbaik =  {'learning_rate': 0.1, 'n_estimators': 150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat model dengan parameter terbaik"
      ],
      "metadata": {
        "id": "QsKLIUJMC_NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = ab2_best_parameter[\"learning_rate\"]\n",
        "n_estimators = ab2_best_parameter[\"n_estimators\"]\n",
        "\n",
        "ab2_tuning = AdaBoostClassifier(learning_rate=learning_rate, n_estimators=n_estimators)"
      ],
      "metadata": {
        "id": "iMwqfnbAa1Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross val akhir"
      ],
      "metadata": {
        "id": "Csez553vDCn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab2_tuning_acc = cross_val_score(ab2_tuning, X2_train, y2_train, scoring=\"accuracy\", cv=10)\n",
        "print(\"Akurasi masing-masing = \", ab2_tuning_acc)\n",
        "print(\"Rata-rata = \", ab2_tuning_acc.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab4139a-2c3b-4226-af2a-40475cb67c9b",
        "id": "TDfjtyJva1Vd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi masing-masing =  [0.69230769 0.69230769 0.61538462 0.84615385 0.84615385 0.76923077\n",
            " 0.84615385 0.92307692 0.69230769 0.84615385]\n",
            "Rata-rata =  0.7769230769230769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AB3"
      ],
      "metadata": {
        "id": "I-fsz3a0a37S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab3_tuning = AdaBoostClassifier()"
      ],
      "metadata": {
        "id": "h7Zvck61a37U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gridsearch (sekitar 3 menit running)"
      ],
      "metadata": {
        "id": "Vitep8Sra37V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_ab3 = GridSearchCV(ab3_tuning,\n",
        "                        parameters_ab,\n",
        "                        scoring='accuracy',\n",
        "                        cv = 10,\n",
        "                        verbose=3)\n",
        "search_ab3.fit(X3_train, y3_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19024e87-5289-4e71-9900-741c8aaecc73",
        "id": "f6sroNTfa37W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=50;, score=0.462 total time=   0.4s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.4s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.4s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=50;, score=0.538 total time=   0.4s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=50;, score=1.000 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.8s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=100;, score=0.846 total time=   0.8s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.8s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=100;, score=0.846 total time=   0.8s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=100;, score=0.769 total time=   0.8s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=100;, score=0.538 total time=   0.8s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=100;, score=0.692 total time=   0.8s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=100;, score=0.769 total time=   0.8s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=100;, score=0.615 total time=   0.8s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=100;, score=1.000 total time=   0.8s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   1.2s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   1.2s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=150;, score=0.846 total time=   1.2s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=150;, score=0.769 total time=   1.2s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=150;, score=0.615 total time=   1.2s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=150;, score=0.692 total time=   1.3s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=150;, score=0.769 total time=   1.2s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=150;, score=0.692 total time=   1.3s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=150;, score=0.923 total time=   1.2s\n",
            "[CV 1/10] END learning_rate=0.01, n_estimators=200;, score=0.615 total time=   1.7s\n",
            "[CV 2/10] END learning_rate=0.01, n_estimators=200;, score=0.846 total time=   1.6s\n",
            "[CV 3/10] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   1.6s\n",
            "[CV 4/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   1.6s\n",
            "[CV 5/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   1.6s\n",
            "[CV 6/10] END learning_rate=0.01, n_estimators=200;, score=0.615 total time=   1.6s\n",
            "[CV 7/10] END learning_rate=0.01, n_estimators=200;, score=0.692 total time=   1.6s\n",
            "[CV 8/10] END learning_rate=0.01, n_estimators=200;, score=0.769 total time=   1.7s\n",
            "[CV 9/10] END learning_rate=0.01, n_estimators=200;, score=0.846 total time=   1.6s\n",
            "[CV 10/10] END learning_rate=0.01, n_estimators=200;, score=0.923 total time=   1.7s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=50;, score=0.692 total time=   0.4s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.8s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   0.8s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.8s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=100;, score=0.923 total time=   0.8s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   0.8s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.8s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=100;, score=0.769 total time=   1.0s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=100;, score=0.846 total time=   1.0s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   1.0s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=100;, score=0.692 total time=   0.8s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   1.2s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=150;, score=0.923 total time=   1.3s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=150;, score=0.769 total time=   1.3s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=150;, score=0.692 total time=   1.3s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=150;, score=0.615 total time=   1.3s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=150;, score=0.769 total time=   1.3s\n",
            "[CV 1/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.7s\n",
            "[CV 2/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   1.7s\n",
            "[CV 3/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   1.7s\n",
            "[CV 4/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.7s\n",
            "[CV 5/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.6s\n",
            "[CV 6/10] END learning_rate=0.1, n_estimators=200;, score=0.692 total time=   1.7s\n",
            "[CV 7/10] END learning_rate=0.1, n_estimators=200;, score=0.769 total time=   1.7s\n",
            "[CV 8/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   1.7s\n",
            "[CV 9/10] END learning_rate=0.1, n_estimators=200;, score=0.615 total time=   1.7s\n",
            "[CV 10/10] END learning_rate=0.1, n_estimators=200;, score=0.846 total time=   1.7s\n",
            "[CV 1/10] END .learning_rate=1, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 2/10] END .learning_rate=1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 3/10] END .learning_rate=1, n_estimators=50;, score=0.923 total time=   0.4s\n",
            "[CV 4/10] END .learning_rate=1, n_estimators=50;, score=0.923 total time=   0.5s\n",
            "[CV 5/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.5s\n",
            "[CV 6/10] END .learning_rate=1, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 7/10] END .learning_rate=1, n_estimators=50;, score=0.769 total time=   0.5s\n",
            "[CV 8/10] END .learning_rate=1, n_estimators=50;, score=0.846 total time=   0.4s\n",
            "[CV 9/10] END .learning_rate=1, n_estimators=50;, score=0.615 total time=   0.4s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=50;, score=0.769 total time=   0.4s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.9s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=100;, score=0.692 total time=   0.9s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=100;, score=0.846 total time=   0.9s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=100;, score=0.923 total time=   0.9s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=100;, score=0.846 total time=   0.8s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=100;, score=0.538 total time=   0.9s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=100;, score=0.846 total time=   0.9s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=100;, score=0.769 total time=   0.9s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=100;, score=0.692 total time=   0.9s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=100;, score=0.846 total time=   0.9s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.3s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=150;, score=0.692 total time=   1.3s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   1.2s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=150;, score=0.615 total time=   1.3s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   1.2s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=150;, score=0.769 total time=   1.3s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=150;, score=0.846 total time=   1.3s\n",
            "[CV 1/10] END learning_rate=1, n_estimators=200;, score=0.692 total time=   1.7s\n",
            "[CV 2/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.7s\n",
            "[CV 3/10] END learning_rate=1, n_estimators=200;, score=0.846 total time=   1.7s\n",
            "[CV 4/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.6s\n",
            "[CV 5/10] END learning_rate=1, n_estimators=200;, score=0.846 total time=   1.6s\n",
            "[CV 6/10] END learning_rate=1, n_estimators=200;, score=0.538 total time=   1.7s\n",
            "[CV 7/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.7s\n",
            "[CV 8/10] END learning_rate=1, n_estimators=200;, score=0.846 total time=   1.7s\n",
            "[CV 9/10] END learning_rate=1, n_estimators=200;, score=0.769 total time=   1.7s\n",
            "[CV 10/10] END learning_rate=1, n_estimators=200;, score=0.846 total time=   1.7s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, estimator=AdaBoostClassifier(),\n",
              "             param_grid={'learning_rate': [0.01, 0.1, 1],\n",
              "                         'n_estimators': [50, 100, 150, 200]},\n",
              "             scoring='accuracy', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akurasi dan parameter terbaik pada Gridsearch"
      ],
      "metadata": {
        "id": "19W6A1lyDFaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab3_best_acc_score = search_ab3.best_score_\n",
        "ab3_best_parameter = search_ab3.best_params_\n",
        "print(\"Akurasi terbaik = \", ab3_best_acc_score)\n",
        "print(\"Parameter terbaik = \", ab3_best_parameter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae53f89-2bac-4a74-87a1-0cee8991a076",
        "id": "O4kknkvUa37X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi terbaik =  0.7923076923076924\n",
            "Parameter terbaik =  {'learning_rate': 1, 'n_estimators': 150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat model dengan parameter terbaik"
      ],
      "metadata": {
        "id": "kia9yVYwDJM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = ab3_best_parameter[\"learning_rate\"]\n",
        "n_estimators = ab3_best_parameter[\"n_estimators\"]\n",
        "\n",
        "ab3_tuning = AdaBoostClassifier(learning_rate=learning_rate, n_estimators=n_estimators)"
      ],
      "metadata": {
        "id": "mseUNeiaa37Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross val score"
      ],
      "metadata": {
        "id": "R86Wo7VqDLFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab3_tuning_acc = cross_val_score(ab3_tuning, X3_train, y3_train, scoring=\"accuracy\", cv=10)\n",
        "print(\"Akurasi masing-masing = \", ab3_tuning_acc)\n",
        "print(\"Rata-rata = \", ab3_tuning_acc.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f06dded8-e5bc-4bdb-d82b-0804dddde911",
        "id": "zfevSad1a37Z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi masing-masing =  [0.76923077 0.69230769 0.84615385 0.84615385 0.84615385 0.61538462\n",
            " 0.84615385 0.84615385 0.76923077 0.84615385]\n",
            "Rata-rata =  0.7923076923076924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non Tuning vs Tuning"
      ],
      "metadata": {
        "id": "odbNyQ6TfsgY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melihat model yang dipilih"
      ],
      "metadata": {
        "id": "Gu296BjoDOId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_yang_dipilih = \"\"\n",
        "\n",
        "if (ab1_tuning_acc.mean() > ab1_non_tuning_acc.mean()):\n",
        "  ab1_model = ab1_tuning\n",
        "  model_yang_dipilih += \"AB1 Tuning, \"\n",
        "else:\n",
        "  ab1_model = ab1_non_tuning\n",
        "  model_yang_dipilih += \"AB1 Non Tuning, \"\n",
        "\n",
        "if (ab2_tuning_acc.mean() > ab2_non_tuning_acc.mean()):\n",
        "  ab2_model = ab2_tuning\n",
        "  model_yang_dipilih += \"AB2 Tuning, \"\n",
        "else:\n",
        "  ab2_model = ab2_non_tuning\n",
        "  model_yang_dipilih += \"AB2 Non Tuning, \"\n",
        "\n",
        "if (ab3_tuning_acc.mean() > ab3_non_tuning_acc.mean()):\n",
        "  ab3_model = ab3_tuning\n",
        "  model_yang_dipilih += \"AB3 Tuning\"\n",
        "else:\n",
        "  ab3_model = ab3_non_tuning\n",
        "  model_yang_dipilih += \"AB3 Non Tuning\"\n",
        "\n",
        "print(\"Model yang dipilih = \", model_yang_dipilih)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS_D5TKWfvXA",
        "outputId": "1da99e3b-61be-41cb-884f-fb4204ae4888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model yang dipilih =  AB1 Tuning, AB2 Tuning, AB3 Tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisasi perbandingan tuning vs non-tuning"
      ],
      "metadata": {
        "id": "GRPF1kBGDQ3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def addlabels(x,y,z):\n",
        "    for i in range(len(x)):\n",
        "      plt.text(i, x[i]+0.02, format(x[i], \".3f\"), ha = 'center')\n",
        "      plt.text(i+0.25, y[i]+0.02, format(y[i], \".3f\"), ha = 'center')\n",
        "      plt.text(i+0.5, z[i]+0.02, format(z[i], \".3f\"), ha = 'center')"
      ],
      "metadata": {
        "id": "6Y1-HLG5nMbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 3\n",
        "ind = np.arange(N) \n",
        "width = 0.25\n",
        "  \n",
        "non_tuning_acc = [ab1_non_tuning_acc.mean(),  ab2_non_tuning_acc.mean(),  ab3_non_tuning_acc.mean()]\n",
        "bar1 = plt.bar(ind, non_tuning_acc, width, color='goldenrod')\n",
        "  \n",
        "tuning_acc = [ab1_tuning_acc.mean(),  ab2_tuning_acc.mean(),  ab3_tuning_acc.mean()]\n",
        "bar2 = plt.bar(ind+width, tuning_acc, width, color='forestgreen')\n",
        "\n",
        "selisih = []\n",
        "for i in range(0, len(non_tuning_acc)):\n",
        "  selisih.append(np.abs(non_tuning_acc[i]-tuning_acc[i]))\n",
        "\n",
        "bar3 = plt.bar(ind+width*2, selisih, width, color = 'firebrick')\n",
        "\n",
        "addlabels(non_tuning_acc, tuning_acc, selisih)\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel('Akurasi')\n",
        "plt.title(\"Perbandingan AdaBoost dengan Akurasi\")\n",
        "  \n",
        "plt.xticks(ind+width,['AB1', 'AB2', 'AB3'])\n",
        "plt.legend( (bar1, bar2, bar3), ('Non Tuning', 'Tuning', 'Selisih') )\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "yvHZaVK-jgMu",
        "outputId": "438e269e-807c-4167-8736-97d00489fd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export"
      ],
      "metadata": {
        "id": "pDHT8dd3V_gI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export model"
      ],
      "metadata": {
        "id": "ZmTKnykxWRPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(ab1_model, 'ab1_model.pkl')\n",
        "joblib.dump(ab2_model, 'ab2_model.pkl')\n",
        "joblib.dump(ab3_model, 'ab3_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0JH6m0UWBN6",
        "outputId": "44ce10f4-97c9-42c9-d739-9b40607d6113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ab3_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}